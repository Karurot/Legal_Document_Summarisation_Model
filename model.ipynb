{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = r\"D:\\Legal_Document_Summarisation\\DATASET\\dataset_test.xlsx\"\n",
    "\n",
    "df = pd.read_excel(filename,index_col=0)\n",
    "df.rename(columns = {'data':'source', 'summary':'target'}, inplace = True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LongTextSummarizationDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_chunk_length, max_summary_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_chunk_length = max_chunk_length\n",
    "        self.max_summary_length = max_summary_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        document = self.data[idx]['source']\n",
    "        summary = self.data[idx]['target']\n",
    "\n",
    "        # Split the document into chunks\n",
    "        chunks = [document[i:i + self.max_chunk_length] for i in range(0, len(document), self.max_chunk_length)]\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            chunks,\n",
    "            max_length=self.max_chunk_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        target = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=self.max_summary_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'labels': target['input_ids'],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_for_long_text(long_text, model, tokenizer, max_chunk_length, max_summary_length):\n",
    "    # Split the long text into chunks\n",
    "    chunks = [long_text[i:i + max_chunk_length] for i in range(0, len(long_text), max_chunk_length)]\n",
    "    generated_summaries = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        input_ids = tokenizer.encode(chunk, return_tensors=\"pt\", max_length=max_chunk_length, padding=\"max_length\", truncation=True)\n",
    "        summary_ids = model.generate(input_ids, max_length=max_summary_length, num_beams=4, early_stopping=True)\n",
    "\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        generated_summaries.append(summary)\n",
    "\n",
    "    full_summary = \" \".join(generated_summaries)\n",
    "    return full_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Legal_Document_Summarisation\\model.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m long_text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mCivil Appeal Nos.3677 3680 of 1986 Etc.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mFrom the Judgment and Order dated 10.3.1986 of the Karnataka High Court in W.P. Nos.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m4053 to 4056 of 1985.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m \u001b[39mP.S.S. Appeals allowed.\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m final_summary \u001b[39m=\u001b[39m summarize_long_text(long_text, use_bert\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m \u001b[39mprint\u001b[39m(final_summary)\n",
      "\u001b[1;32md:\\Legal_Document_Summarisation\\model.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m text_chunks:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     inputs \u001b[39m=\u001b[39m tokenizer(chunk, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39mmax_chunk_length, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     summary_ids \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(inputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_length\u001b[39m=\u001b[39;49mmax_summary_length, num_beams\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     summary \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(summary_ids[\u001b[39m0\u001b[39m], skip_special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Legal_Document_Summarisation/model.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     summaries\u001b[39m.\u001b[39mappend(summary)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1685\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1678\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1679\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1680\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[0;32m   1681\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1682\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1683\u001b[0m     )\n\u001b[0;32m   1684\u001b[0m     \u001b[39m# 13. run beam search\u001b[39;00m\n\u001b[1;32m-> 1685\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbeam_search(\n\u001b[0;32m   1686\u001b[0m         input_ids,\n\u001b[0;32m   1687\u001b[0m         beam_scorer,\n\u001b[0;32m   1688\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1689\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1690\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[0;32m   1691\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[0;32m   1692\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[0;32m   1693\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1694\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1695\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1696\u001b[0m     )\n\u001b[0;32m   1698\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SAMPLE:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     logits_warper \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_logits_warper(generation_config)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:3024\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   3022\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m-> 3024\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[0;32m   3025\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[0;32m   3026\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   3027\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   3028\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   3029\u001b[0m )\n\u001b[0;32m   3031\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3032\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1235\u001b[0m, in \u001b[0;36mBertLMHeadModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1233\u001b[0m     use_cache \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1235\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1236\u001b[0m     input_ids,\n\u001b[0;32m   1237\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1238\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1239\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1240\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1241\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1242\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1243\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[0;32m   1244\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1245\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1246\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1247\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1248\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1249\u001b[0m )\n\u001b[0;32m   1251\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1252\u001b[0m prediction_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[1;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    605\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    613\u001b[0m         hidden_states,\n\u001b[0;32m    614\u001b[0m         attention_mask,\n\u001b[0;32m    615\u001b[0m         layer_head_mask,\n\u001b[0;32m    616\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    617\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    618\u001b[0m         past_key_value,\n\u001b[0;32m    619\u001b[0m         output_attentions,\n\u001b[0;32m    620\u001b[0m     )\n\u001b[0;32m    622\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    540\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pytorch_utils.py:240\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    551\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 552\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:464\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 464\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    465\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    466\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertLMHeadModel\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertLMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "def summarize_long_text(long_text, max_chunk_length=125, max_summary_length=240, use_bert=True):\n",
    "    # Split the long text into smaller chunks\n",
    "    text_chunks = [long_text[i:i + max_chunk_length] for i in range(0, len(long_text), max_chunk_length)]\n",
    "    summaries = []\n",
    "\n",
    "    if use_bert:\n",
    "        # Generate summaries using BERT-based model for each chunk\n",
    "        for chunk in text_chunks:\n",
    "            inputs = tokenizer(chunk, return_tensors=\"pt\", max_length=max_chunk_length, padding=\"max_length\", truncation=True)\n",
    "            summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_summary_length, num_beams=4, early_stopping=True)\n",
    "            summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            summaries.append(summary)\n",
    "    else:\n",
    "        # Alternatively, you can use extractive summarization with LexRank\n",
    "        # Make sure to install the sumy library: pip install sumy\n",
    "        parser = PlaintextParser.from_string(long_text, Tokenizer(\"english\"))\n",
    "        summarizer = LexRankSummarizer(Stemmer(\"english\"))\n",
    "        summarizer.stop_words = get_stop_words(\"english\")\n",
    "        \n",
    "        for sentence in summarizer(parser.document, 3):  # Adjust the number of sentences in the summary\n",
    "            summaries.append(str(sentence))\n",
    "\n",
    "    # Combine the summaries from each chunk into a single summary\n",
    "    full_summary = \" \".join(summaries)\n",
    "    return full_summary\n",
    "\n",
    "# Example usage\n",
    "long_text = \"\"\"Civil Appeal Nos.3677 3680 of 1986 Etc.\n",
    "From the Judgment and Order dated 10.3.1986 of the Karnataka High Court in W.P. Nos.\n",
    "4053 to 4056 of 1985.\n",
    "Shanti Bhushan, Dr. Y.S. Chitale, H.B. Datar, K.R. Nagaraja, 1011 R.S. Hegde, R.B. Datar, S.S. Jawali, B.P. Singh, N.D.B. Raju, R.P., Wadhwani, Aruneshwar Gupta, Swaraj Kaushal, KMM Khan, S.R. Setia, A.T.M. Sampath and C.S. Vaidyanathan for the appearing parties.\n",
    "The Judgment of the Court was delivered by CHINNAPPA REDDY, J.\n",
    "Special leave granted in all the cases.\n",
    "These appeals raise common questions of law and may therefore, be disposed of by a common judgment.\n",
    "In exercise of its powers under section 63(7) of the , the Central Government specified 50 as the number of 'All India Tourist Vehicle Permits ' which may be granted by the Karnataka State Transport Authority.\n",
    "By section 24 of Amending Act 47 of 1978, a proviso to section 63(7) was introduced.\n",
    "We are concerned in these appeals with the vires and interpretation of this proviso.\n",
    "By the time the proviso came into force, 36 permits had been granted by the Karnataka State Transport Authority and 14 remained to be granted.\n",
    "There were as many as 495 applications for the grant of these 14 permits.\n",
    "By an order dated February 1, 1984, the Supreme Court directed the Karnataka State Transport Authority to dispose of these applications.\n",
    "The State Transport Authority, by its proceedings dated April 30, 1984, granted 11 out of the 14 permits to the Karnataka State Tourism Development Corporation, one permit to the Indian Tourism Development Corporation and two permits to the Karnataka State Road Transport Corporation.\n",
    "A number of appeals were preferred to the Karnataka State Transport Appellate Tribunal.\n",
    "The Tribunal by its order dated February 28, 1985 set aside the grant of the two permits in favour of the Karnataka State Road Transport Corporation, set aside the grant of three out of eleven permits to the Karnataka State Tourism Development Corporation and instead granted three permits to private operators and increased the number of permits granted to the Indian Tourism Development Corporation from one to three.\n",
    "The Tribunal took the view that having regard to the rule of preference enunciated by the proviso to section 63(7), the applications from the 'non preferred ' category had to be excluded as the number of applications from the applicants who were required to be given preference exceeded the number of permits to be granted.\n",
    "It was on that ground that the grant of two permits to the Karnataka State Road Transport Corporation was set aside, though the Appellate Tribunal had no doubt regarding the resources and ability of that corporation to operate the tourist services.\n",
    "It was on that ground again, it was so stated by the Tribunal, that some of the appellants 1012 before the Tribunal had to be denied the grant of permits though otherwise they would have been entitled to the grant of permits having regard to their expertise, experience and resources.\n",
    "The Tribunal rejected their appeals regretfully.\n",
    "A large number of applicants filed writ petitions in the High Court.\n",
    "The writ petitions were rejected by the High Court on the ground that the preference contemplated by the proviso to section 63(7) contemplated exclusion of the 'non preferred ' class if sufficient number of applicants from the preferred classes were available.\n",
    "The decision of this Court in Sher Singh vs Union of India, ; was distinguished on the ground that in that case the court interpreted the word 'preference ' occurring in section 47(1 H) in the back ground of the provisions of Chapters IV and IV A of the Act, under the former of which the State Transport Undertaking would have preference whereas under the latter the State Transport Undertaking would have a monopoly.\n",
    "The Karnataka State Road Transport Corporation, the Karnataka State Tourism Development Corporation and some other private operators have filed these appeals by special leave of this Court under article 136 of the Constitution.\n",
    "Shri Shanti Bhushan, learned counsel for the Karnataka State Road Transport Corporation, Dr. Chitley, learned counsel for some of the private operators, Shri Datar, learned counsel for the Karnataka State Tourism Development Corporation, Shri Sampat and Shri Javali, learned counsel for other private operators submitted that the State Transport Appellate Tribunal and the High Court were wrong in distinguishing the decision of this court in Sher Singh 's case and that the true position was that on a correct interpretation of the proviso to sec.\n",
    "63(7), the preference became operative only if other things were equal.\n",
    "It was also urged that the fourth sub clause of the proviso offended article 14 and had to be struck down.\n",
    "Shri C.S. Vaidyanathan, learned counsel for some of the preferred private operators urged that the view taken by the High Court and the State Transport Appellate Tribunal was correct and that the fourth sub clause of the proviso to section 63(7) did not offend article 14 of the Constitution.\n",
    "We may now glance at some of the relevant provisions of the . section 2(33) defines a \"transport vehicle\" as meaning a \"public service vehicle or a goods vehicle\".\n",
    "A \"public service vehicle\" is defined in section 2(25) as \"any motor vehicle used or adapted to be used for the carriage of passengers for hire or reward, and includes a motor cab, contract carriage, and stage carriage\".\n",
    "A \"motor car\" is defined in section 2(16) as \"any motor vehicle other than a transport vehicle, 1013 omni bus, road roller, tractor, motor cycle or invalid carriage\".\n",
    "A \"contract carriage\" is defined as, broadly, a motor vehicle which carries a passenger or passengers for hire or reward under a contract. \"Tourist vehicle\" is defined by section 2(29 A) as \"a contract carriage constructed or adapted and equipped and maintained in accordance with such specifications as the State Government may, by notification in the Official Gazette, specify in this behalf\".\n",
    "\"Stage carriage\" is defined by section 2(29) as \"a motor vehicle carrying or adapted to carry more than six persons excluding the driver which carries passengers for hire or reward at separate fares paid by or for individual passengers, either for the whole journey or for stages of the journey.\" Chapter IV, sections 42 to 68, deals with \"Control of Transport vehicles\".\n",
    "Section 42 prescribes permits for the use of a transport vehicle in any public place.\n",
    "Sections 46, 47 and 48 deal with the grant of stage carriage permits.\n",
    "Section 47(1) prescribes the matters to be taken into consideration in granting stage carriage permits and the first consideration, naturally, is \"the interest of the public generally.\n",
    "\" The proviso to section 47(1) prescribes that, other things being equal, a registered cooperative society and a person possessing a licence for driving transport vehicles shall be given preference over individual owners in granting stage carriage permits.\n",
    "Section 47(1 A) enables the State Government to reserve a certain percentage of stage carriage permits for the Scheduled Castes and Scheduled Tribes.\n",
    "Section 47(1 C) enables the State Government to reserve a certain percentage of stage carriage permits to persons belonging to economically weaker sections of the community.\n",
    "Section 47(1 H) prescribes that notwithstanding anything contained in the section, an application for stage carriage permit from a State Transport undertaking for operating in any inter State route shall be given preference overall other applications, provided, of course, the authority is satisfied that the State Transport Undertaking would be able to operate in the inter State route without detriment to its responsibility for providing efficient and adequate road transport services in any notified area or notified route.\n",
    "Sections 49, 50, 51 deal with the grant of contract carriage permits.\n",
    "Section 52 and 53 deal with private carrier 's permit and sections 54, 55 and 56 deal with public carrier 's permit.\n",
    "Section 57 deals, generally with the procedure to be followed in applying for and granting permits.\n",
    "Section 63(1) stipulates, broadly, that a permit granted by the Regional Transport Authority of any one region shall not be valid in any other region, unless the permit has been countersigned by the Regional Transport Authority of that other region, and a permit granted in any one State shall not be valid in any other State unless countersigned by the State Transport Authority of 1014 that other State or by the Regional Transport Authority concerned.\n",
    "Section 63(7) is the provision with whose interpretation and vires we are primarily concerned in this case.\n",
    "It is as follows: \"(7) Notwithstanding anything contained in sub section(1) but subject to any rules that may be made under this Act, any State Transport Authority may, for the purpose of promoting tourism, grant permits valid for the whole or any part of India, in respect of such number of tourist vehicles as the Central Government may, in respect of that State, specify in this behalf, and the provisions of Sections 49, 50, 51, 57, 58, 59, 59 A, 60, 61 and 64 shall, as far as may be, apply in relation to such permits: Provided that preference shall be given to applications for permits from (i) the India Tourism Development Corporation; (ii) a State Tourism Development Corporation; (iii) a State Tourist Department; (iv) such operators of tourist cars, or such travel agents, as may be approved in this behalf by the Ministry of the Central Government dealing in tourism.\n",
    "\" Section 68 enables the State Government to make rules for the purpose of carrying into effect the provisions of Chapter IV.\n",
    "Chapter IV A relates to \"special provisions relating to State Transport Under takings.\n",
    "\" Sections 68 C, 68 D and 68 E provide for the preparation and publication of schemes of road transport service to be provided by State Transport Undertakings, the procedure to be followed, etc.\n",
    "Section 68 F(1) prescribes that where, in pursuance of an approved scheme, a State Transport Undertaking applies for a stage carriage permit, a contract carriage permit or a public carrier 's permit in respect of a notified area or notified route, such permit shall be granted to the State Transport Undertaking by the State Transport Authority in a case where the said area or route lies in more than one region and the Regional Transport Authority in any other case.\n",
    "This is to be so notwithstanding anything to the contrary contained in Chapter IV.\n",
    "1015 The general scheme of the Act in the matter of grant of permits for stage carriages and contract carriages appears to be that except in the case of a notified route or notified area, where under section 68 F(1) the permit has to be necessarily granted to the State Transport Undertaking, in all other cases, the claims of all eligible applicants must be considered on merits, applying the rules of preference wherever the claims are approximately equal.\n",
    "Except in the case of a notified route or notified area, the application of no applicant may be altogether excluded from consideration on the sole ground that another applicant is entitled to preference under one or the other provisions of the statute.\n",
    "The proviso to section 47(1) for example, provides that other conditions being equal, an application for a stage carriage permit from a cooperative society or a person holding a valid licence for driving transport vehicles shall as far as may be, be given preference over applications from individual owners.\n",
    "There is no problem here since the proviso itself says that the rules of preference will apply only if other conditions are equal.\n",
    "Section 47(1 H) also enunciates a rules of preference and says that an application for stage carriage permit from State Transport Undertaking for operating in any inter State route shall be given preference overall other applications.\n",
    "While it is true that section 47(1 H) does not expressly refer to \"other things being equal\", it appears to be implicit in the provision that other things are equal.\n",
    "The rule is a rule of preference and not a rule of exclusion.\n",
    "Section 47(1 H) does not say, for example, like section 68 F(1) that the permit shall be granted to the State Transport Undertaking.\n",
    "That is how section 47(1 H) was interpreted in Sher Singh 's case.\n",
    "Desai, J., speaking for the court observed: \"However, when an application for a permit is made under Chapter IV, the Undertaking has to compete with private operators who may as well make an application for permit.\n",
    "When the Undertaking applies for permit under Chapter IV, it must satisfy the Regional Transport Authority that it is better suited than the private operator to render transport facility to the travelling public.\n",
    "47(1 H) however, provides that in the case of inter State route, the Undertaking will have preference in the matter of stage carriage permit.\n",
    "Does preference of this nature deny equality guaranteed by article 14? The expression 'preference ' amongst others means prior right, advantage, precedence etc.\n",
    "But how would it be possible to give precedence to one over the other.\n",
    "It signifies that other things being equal, 1016 one will have preference over the others.\n",
    "When an application for a stage carriage permit is being processed as required by sec.\n",
    "47, the application of the Undertaking for an inter State route shall be examined as application of any other private operator.\n",
    "Their merits and demerits must be ascertained keeping in view the requirements of (a) to (f) of section 47(1) and after comparing the merits and demerits of both, not with the yard stick of mathematical accuracy, but other things being equal, the application of the Undertaking will have preference over others.\n",
    "Qualitative and quantitative comparison on broad features of passenger transport facility such as fleet, facilities to travelling public and other relevant consideration may be undertaken and after balancing these factors other things being equal, the application of the Undertaking shall be given preference over other applicants.\n",
    "There is no question of eliminating private operators merely because the Undertaking applies for a stage carriage permit under Chapter IV.\n",
    "That situation is catered to under Chapter IV A.\n",
    "In an application under Chapter IV, Corporation has to enter the arena like any other applicant, face the competition and come up to the level of other private operators intending to obtain stage carriage permits and then in respect of the route in question claim preference.\n",
    "Would this statutory provision violate equality guaranteed by article 14? The answer is obviously in the negative.\" . . . . . . . . . . . . . . . . . \". . . let it be made clear that while considering the application for stage carriage permit under section 47, the private operator has an equal chance to get a permit even on inter State route if it shows that the Undertaking is either unable to provide efficient and economical service or that the private operator is better equipped to render the same.\n",
    "Preference in this context would mean that other things generally appearing to be qualitatively and quantitatively equal though not with mathematical accuracy, statutory provision will tilt the balance in favour of the Undertaking.\n",
    "\" What has been said by the Court with reference to the preference 1017 provided for in section 47(1 H) applies with equal force to the preference provided for by the proviso to section 63(7).\n",
    "In the judgment under appeal, the High Court attempted to distinguish the decision of this Court in Sher Singh 's case on the ground that any other interpretation would have wiped out the difference between Chapter IV and Chapter IV A.\n",
    "We do not think the High Court was right in distinguishing the case in that fashion.\n",
    "The reference to Chapter IV A there was for the purpose of contrasting the exclusion contemplated by section 68.F(1) with the preference to be given under section 47 (1 H) and so to interpret the word 'preference ' occurring in section 47(1 H).\n",
    "We have no hesitation in saying that all that has been said about 'preference ' in Sher Singh 's case in relation to section 47(1 H) applies mutatis mutandis to the preference contemplated by the proviso to section 63(7).\n",
    "Since the State Transport Appellate Tribunal and the High Court have failed to consider the merits of the claims of the Karnataka State Road Transport Corporation and the private operators who did not get a certificate of approval from the Central Government, because of the rule of preference contained in proviso to section 63(7), the proper course for us is to set aside the orders of the State Transport Appellate Tribunal and the High Court and to direct the State Transport Appellate Tribunal to re hear the appeals and dispose them of in accordance with law, after considering the claims of the eligible applicants in the manner indicated in Sher Singh 's case and now.\n",
    "A question was raised before us about the vires of the fourth clause of the proviso to section 63(7).\n",
    "Clauses (i) to (iii) of the proviso providing for preference to be given to applications for permits from the Indian Tourism Development Corporation, the State Tourism Development Corporation and the State Tourist Department were not questioned, but the preference provided for by clause (iv) and to be given to \"such operators of tourist cars, or such travel agents, as may be approved in this behalf by the Ministry dealing in tourism\" was questioned as an infringement of article 14 of the Constitution.\n",
    "We find it difficult to sustain this clause and uphold its validity.\n",
    "The very idea that a Tribunal created by a statute for the purpose of considering rival claims and granting permits on merits should be compelled to give peference to persons securing the approval of the executive Government, appears to us to be arbitrary and unreasonable.\n",
    "To the extent that it goes, the clause pre empts the decision of the designated tribunal by executive discretion.\n",
    "It was said that the clause contained sufficient guidelines for the exercise of discretion in granting approval by the Central Government.\n",
    "It was said that the object of the proviso to section 1018 63(7) was very obviously the promotion of tourism and the approval of the Central Government would be given to those operators of tourist cars and travel agents who may be expected to serve that purpose.\n",
    "It is difficult to agree with these submissions.\n",
    "In the first place, clause (d), it is seen, provides for a preference, not to operators of tourist vehicles but to operators of tourist cars and travel agents.\n",
    "Though the permits to be granted are for tourist vehicles, the preference is confined to operators of tourist cars and travel agents.\n",
    "One may understand a preference granted to operators of tourist vehicles but it is difficult to understand why preference should be given to operators of tourist cars in the matter of granting permits for tourist vehicles which may well be omnibuses required to travel long distances.\n",
    "Surely it cannot be said that experience of running a tourist taxi is a better qualification than running a tourist bus when the question of granting permits for tourist vehicles arises.\n",
    "The High Court of Karnataka tided over the difficulty by interpreting the expression \"tourist cars\" as meaning \"tourist vehicles\".\n",
    "It is difficult to agree with the interpretation of the Karnataka High Court having regard to the definitions of \"Transport Vehicle\" and \"motor car\" contained in section 2(29 A) and section 2(16) respectively.\n",
    "While a tourist vehicle may include a motor car, a motor car, by definition, excludes an omnibus.\n",
    "In the second place, we have no indication as to the manner in which the approval of the Central Government is to be sought and granted and the considerations which are expected to weigh with the Central Government.\n",
    "Shri C.S. Vaidyanathan, learned counsel for the 'Preferred ' Operators has placed before us 'a Scheme for granting approval to tourist transport operators in India. ' The scheme makes no reference to the proviso to sec.\n",
    "63(7) of the .\n",
    "On the other hand, it mentions that approval carries with it certain privileges, such as, allotment of ex STC vehicles and that it is, therefore, necessary that the department is able to exercise some control on the functioning of these operators.\n",
    "The terms and conditions to be fulfilled are that 'the party must have been in the car hire business for a period of 2 years with the help of cars of indigenous make or cars obtained from elsewhere and should have sufficient contacts with travel agencies hoteliers/airlines, etc.\n",
    "and should be financially sound or that they should be owning and operating five vehicles as tourist taxies of either indigenous make or acquired from elsewhere regardless of the period in the car hire business or that they should be ex Defence Service personnel, who satisfy certain prescribed conditions.\n",
    "It is seen that the scheme excludes omnibus operators and requires applicants to have 1019 either two years ' experience in the car hire business with contacts in the tourist business or to own five tourist taxies.\n",
    "There are no guidelines as to how the discretion to grant approval is to be exercised once the minimum conditions are fulfilled.\n",
    "The matter appears to be left to the total discretion of the Central Government, virtually as we said, pre empting the decision of the statutory tribunal.\n",
    "We think that clause (iv) of the proviso to section 63(7) is unconstitutional and we so declare it.\n",
    "In the result we set aside the orders of the State Transport Appellate Tribunal and the High Court and direct the State Transport Appellate Tribunal to hear the appeals in the light of what we have said.\n",
    "P.S.S. Appeals allowed.\n",
    "\"\"\"\n",
    "final_summary = summarize_long_text(long_text, use_bert=True)\n",
    "print(final_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
